{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CkptedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DoTLMViz import CkptedTransformer\n",
    "\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tokenizer and the checkpointed transformer from the pretrained gpt models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NITRO5\\miniconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = CkptedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tokens to pass into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\"alpha beta gamma\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get logits and the cache of the model by running the model on the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = model.run_with_ckpts(tokens[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access activations through the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [8.7884e-01, 1.2116e-01, 0.0000e+00],\n",
       "          [4.6817e-01, 2.1589e-01, 3.1595e-01]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [6.6951e-04, 9.9933e-01, 0.0000e+00],\n",
       "          [1.5889e-03, 4.4212e-02, 9.5420e-01]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [8.2392e-01, 1.7608e-01, 0.0000e+00],\n",
       "          [7.3795e-01, 1.6675e-01, 9.5302e-02]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.3172e-01, 7.6828e-01, 0.0000e+00],\n",
       "          [4.6818e-02, 1.0776e-02, 9.4241e-01]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.0763e-01, 2.9237e-01, 0.0000e+00],\n",
       "          [7.3089e-02, 6.2097e-02, 8.6481e-01]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.1252e-01, 7.8748e-01, 0.0000e+00],\n",
       "          [2.6881e-01, 2.4206e-02, 7.0698e-01]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [8.8251e-01, 1.1749e-01, 0.0000e+00],\n",
       "          [6.2809e-01, 2.1542e-01, 1.5648e-01]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [9.6287e-01, 3.7126e-02, 0.0000e+00],\n",
       "          [5.6373e-01, 3.5041e-01, 8.5858e-02]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.9798e-01, 2.0202e-01, 0.0000e+00],\n",
       "          [4.9780e-01, 2.5206e-01, 2.5014e-01]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [8.6681e-01, 1.3319e-01, 0.0000e+00],\n",
       "          [6.7614e-01, 2.8460e-01, 3.9259e-02]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [6.0034e-01, 3.9966e-01, 0.0000e+00],\n",
       "          [5.3544e-01, 2.2628e-01, 2.3828e-01]],\n",
       "\n",
       "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [5.8316e-01, 4.1684e-01, 0.0000e+00],\n",
       "          [4.0898e-01, 4.0561e-01, 1.8540e-01]]]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache[\"blocks.0.attn.ckpt_pattern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
